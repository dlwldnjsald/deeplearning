{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d32824e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers 모듈 설치\n",
    "# pip install transformers\n",
    "# 모델명: google/vit-base-patch16-224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34962717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: Egyptian cat\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "# model predicts one of the 1000 ImageNet classes\n",
    "predicted_class_idx = logits.argmax(-1).item()\n",
    "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcd17e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델명: facebook/detr-resnet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ce7751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected traffic light with confidence 0.984 at location [938.32, 649.8, 963.71, 695.6]\n",
      "Detected person with confidence 0.992 at location [872.5, 901.74, 934.02, 1072.96]\n",
      "Detected person with confidence 0.918 at location [1114.77, 916.1, 1175.01, 1079.41]\n",
      "Detected person with confidence 0.93 at location [1115.2, 911.77, 1173.35, 1079.51]\n",
      "Detected person with confidence 0.931 at location [1294.0, 917.98, 1347.73, 1059.47]\n",
      "Detected person with confidence 0.935 at location [1172.62, 909.66, 1214.56, 1043.15]\n",
      "Detected person with confidence 0.941 at location [1090.04, 730.46, 1179.47, 856.33]\n",
      "Detected car with confidence 0.996 at location [677.88, 931.63, 781.33, 998.13]\n",
      "Detected car with confidence 0.998 at location [356.99, 912.97, 586.5, 1047.51]\n",
      "Detected person with confidence 0.976 at location [1057.9, 905.58, 1106.6, 1079.4]\n",
      "Detected person with confidence 0.916 at location [924.7, 891.87, 974.19, 998.2]\n",
      "Detected person with confidence 0.961 at location [927.49, 897.07, 979.31, 1073.58]\n",
      "Detected person with confidence 0.987 at location [1007.39, 910.99, 1064.98, 1079.27]\n",
      "Detected traffic light with confidence 0.926 at location [1000.46, 823.34, 1027.6, 857.12]\n"
     ]
    }
   ],
   "source": [
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "#url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "url = \"https://media.triple.guide/triple-cms/c_limit,f_auto,h_2048,w_2048/3af8395b-4e75-45fe-8836-32dc84569622.jpeg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# you can specify the revision tag if you don't want the timm dependency\n",
    "#timm 종속성을 원하지 않는 경우 revision 태그를 지정할 수 있습니다\n",
    "processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
    "model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\", revision=\"no_timm\")\n",
    "\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# convert outputs (bounding boxes and class logits) to COCO API\n",
    "# let's only keep detections with score > 0.9\n",
    "#출력을 COCO API로 변환합니다 (바운딩 박스 및 클래스 로짓)\n",
    "#점수가 0.9 이상인 검출만 유지합니다\n",
    "target_sizes = torch.tensor([image.size[::-1]])\n",
    "results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
    "\n",
    "for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "    box = [round(i, 2) for i in box.tolist()]\n",
    "    print(\n",
    "            f\"Detected {model.config.id2label[label.item()]} with confidence \"\n",
    "            f\"{round(score.item(), 3)} at location {box}\"\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9fef31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델명: nvidia/segformer-b0-finetuned-ade-512-512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b65fe55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 150, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "from transformers import SegformerImageProcessor, SegformerForSemanticSegmentation\n",
    "from PIL import Image\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "# 모델과 프로세서 초기화\n",
    "processor = SegformerImageProcessor.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-ade-512-512\")\n",
    "\n",
    "# 이미지 로드\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "# 이미지 처리\n",
    "inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "# 모델 예측\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# 로짓 추출\n",
    "logits = outputs.logits  # shape (batch_size, num_labels, height/4, width/4)\n",
    "\n",
    "print(logits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3bb06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델명: openai-community/gpt2\n",
    "# TensorFlow로 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd2d15f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Jiwon Lee. I am from South Korea and  I am a Korean American. My family is Korean Americans.\n",
      "I have been living in the United States for over 10 years. In the past I have lived in a\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
    "import tensorflow as tf\n",
    "\n",
    "# 토크나이저와 모델 초기화\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = TFGPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# 입력 텍스트\n",
    "text = \"My name is Jiwon Lee. I am from South Korea and \"\n",
    "encoded_input = tokenizer(text, return_tensors='tf')\n",
    "\n",
    "# 텍스트 생성\n",
    "output_sequences = model.generate(\n",
    "    input_ids=encoded_input['input_ids'],\n",
    "    max_length=50,  # 생성할 텍스트의 최대 길이\n",
    "    num_return_sequences=1,  # 생성할 텍스트의 수\n",
    "    no_repeat_ngram_size=2,  # 반복 방지\n",
    "    top_k=50,  # 상위 k개의 단어 중에서 선택\n",
    "    top_p=0.95,  # 누적 확률이 0.95 이하인 단어들 중에서 선택\n",
    "    temperature=0.7  # 샘플링 온도\n",
    ")\n",
    "\n",
    "# 생성된 텍스트 디코딩\n",
    "generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
